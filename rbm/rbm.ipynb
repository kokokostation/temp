{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "У нас есть некоторая выборка $X$ из распределения $p$ на бинарных векторах $v \\in \\{0, 1\\}^m$. Наша задача в том, чтобы выучить это распределение. Выучить значит оценить $p$ и научиться из него семплировать. Также RBM позволит семплировать из всевозможных условных распределений типа $p(v_1, v_2 | v_3, ..., v_m)$, позволит, подобно автоэнкодеру или PCA, получать некоторое сжатое представление объектов. Наверное, есть ещё много применений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "<img src=\"13.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC. Gibbs sampling\n",
    "\n",
    "Это набор техник, позволяющих семплировать из сложных распределений. Для обучения и применения RBM нам понадобится знать, что такое Gibbs sampling.\n",
    "\n",
    "**Марковские цепи**\n",
    "\n",
    "$p(x_1, ..., x_n) = p_1(x_1) \\cdot p_2(x_2 | x_1) \\cdot ... \\cdot p_n(x_n | x_{n - 1})$ -- распределение каждого следующего состояния зависит только от предыдущего состояния и номера шага.\n",
    "\n",
    "Теперь если $p_2 = p_3 = ... = p_n = q$, то марковская цепь называется гомогенной.\n",
    "$p_2(x_2) = \\int p(x_1, ..., x_n) dx_1 dx_3 ... dx_n = \\int q(x_2 | x_1) p(x_1) dx_1 = Qp_1$ -- $Q$ линейный оператор, аналог умножения на матрицу для непрерывного случая. В дискретных марковских цепях, собственно, распределение на $n + 1$ шаге получается из распределения на $n$ шаге домножением на матрицу.\n",
    "\n",
    "$p_n = Q^{n - 1} p_1$\n",
    "\n",
    "Марковская цепь называется **эргодической**, если $\\exists r: \\forall p_1 \\lim \\limits_{n \\rightarrow \\inf} Q^n p_1 = r$.\n",
    "\n",
    "**Теорема** Если $\\forall x, y: q(y | x) > 0$, то марковская цепь -- эргодическая\n",
    "\n",
    "**Утверждение** Если $\\forall x, y$ выполнено соотношение $q(y | x) p(x) = q(x | y) p(y)$, то $p$ -- стационарное распределние для марковской цепи, задаваемой $q$. Соотношение называется уравнением детального баланса.\n",
    "\n",
    "Действительно, \n",
    "<center>\n",
    "    $(Qp)(y) = \\int q(y | x) p(x) dx = \\int q(x | y) p(y) dx = p(y)$\n",
    "</center>\n",
    "\n",
    "Теперь сформулируем более слабое достаточное условие эргодичности для случая конечного пространства состояний. Для непрерывного случая, формулировка аналогичная, но более громоздкая и нам не понадобится.\n",
    "\n",
    "Марковская цепь является **неприводимой**, если для любой пары состояний существует ненулевая вероятность добраться из одного в другое за конечное число шагов, формально $\\forall i, j \\in \\Omega\\ \\exists k > 0 : P(x_k = j | x_0 = i) > 0$ \n",
    "\n",
    "Марковская цепь является **апериодичной**, если для каждого состояния, моменты времени, в которые в нем можно оказаться распределены нерегулярно, формально $\\forall i \\in \\Omega:\\ GCD\\{k | P(x_k = i | x_0 = i) > 0\\} = 1$\n",
    "\n",
    "**Теорема** Если марковская цепь неприводима и апериодична, а $r$ -- стационарное распределение, то  $\\forall p_1 \\lim \\limits_{n \\rightarrow \\inf} Q^n p_1 = r$\n",
    "\n",
    "Итак, суть методов MCMC в том, чтобы для $p$, из которого мы хотим семплировать, подобрать $q$, такое что выполняется уравнение детального баланса и выполняются достаточные условия эргодичности. Тогда начав из произвольной точки и переходя по Марковской цепи, начиная с некоторой итерации $i >> 1$ мы начнем получать семплы из распределения, очень близкого к $p$. \n",
    "\n",
    "**Gibbs sampling**\n",
    "\n",
    "Пусть есть строго положительное распределение $\\pi(x_1, ..., x_n)$ с конечным носителем $\\Lambda^n$, и семплировать мы умеем только из $\\pi(x_i | (x_v)_{v \\in V \\backslash i})$. Построим марковскую цепь, которая позволит нам семплировать из $\\pi$. Для этого достаточно определить вероятность перехода.\n",
    "\n",
    "Возмем любое строго положительное распределение вероятностей $q$ на $\\{1, ..., n\\}$. Пусть мы находимся в точке $(x_1^k, ..., x_n^k)$, разыграем индекс $i$ с помощью $q$, затем положим $\\forall j \\neq i:\\ x_j^{k + 1} = x_j^k$, а $x_i^{k + 1}$ разыграем из $\\pi(x_i | (x_v^k)_{v \\in V \\backslash i})$\n",
    "\n",
    "<img src=\"1.png\">\n",
    "\n",
    "Проверка уравнения детального баланса:\n",
    "\n",
    "<img src=\"2.png\">\n",
    "\n",
    "Неприводимость очевидна из строгой положительности $\\pi, q$. Апериодичность из того, что $p_{xx} > 0$\n",
    "\n",
    "Часто обходятся без $q$ и просто проходятся по индексам в порядке очереди, такая схема тоже сходится к заданному распределению (без доказательства)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRF\n",
    "\n",
    "<img src=\"3.png\">\n",
    "\n",
    "В каждой вершине находится случайная величина, при этом выполнено локальное Марковское свойство $p(x_v | (x_w)_{w \\in V \\backslash \\{v\\}}) = p(x_v | (x_w)_{w \\in N_v})$\n",
    "\n",
    "<img src=\"4.png\">\n",
    "\n",
    "$E$ -- некоторая функция, которая зависит от параметра $\\theta$, MRF можно обучать путем максимизации правдоподобия: $p(X | \\theta)$. Правдоподобие же можно оптимизировать градиентным спуском. Для этого необходимо уметь считать градиент $\\frac{\\partial p}{\\partial \\theta}$ (для удоства работают с логправдоподобием):\n",
    "\n",
    "<img src=\"5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM\n",
    "\n",
    "RBM -- это MRF следующего вида:\n",
    "\n",
    "<img src=\"6.png\">\n",
    "\n",
    "Так как энергия $E$ факторизуется по кликам (в данном графе клики -- всевозможные пары вершин $(h_i, v_j)$), то она имеет следующий вид:\n",
    "<center>\n",
    "    $E(h, v) = \\sum \\limits_{i, j} (d_{ij} h_i v_j + e_{ij} (1 - h_i) v_j + s_{ij} h_i (1 - v_j) + t_{ij} (1 - h_i) (1 - v_j))$, и с точностью до константы, которая нас не волнует<br>\n",
    "    $E(h, v) = \\sum \\limits_{i, j} w_{ij} h_i v_j + \\sum \\limits_j b_j v_j + \\sum \\limits_i c_i h_i$\n",
    "</center>\n",
    "\n",
    "Выражения для рассчета условных вероятностей на видимые/скрытые переменные:\n",
    "\n",
    "<img src=\"7.png\">\n",
    "<img src=\"8.png\">\n",
    "\n",
    "Посчитаем градиент логправдоподобия:\n",
    "\n",
    "<img src=\"9.png\">\n",
    "<img src=\"10.png\">\n",
    "<img src=\"11.png\">\n",
    "\n",
    "Теперь единственная проблема -- научиться считать матожидание по $p(v)$, утверждается, что это можно эффективно сделать по следующей схеме:\n",
    "\n",
    "<img src=\"12.png\">\n",
    "\n",
    "где $v^{(k)}$ -- семпл, полученный на $k$-ой итерации Gibbs sampling из $v^{(0)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import datasets\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampling_generator(sampler, state, steps):\n",
    "    for i in range(steps):\n",
    "        state = sampler.sample(state, i % len(state))\n",
    "        yield state\n",
    "    \n",
    "\n",
    "def range_gibbs_sampling(sampler, state, begin, end):\n",
    "    return list(gibbs_sampling_generator(sampler, state, end))[begin:]\n",
    "\n",
    "\n",
    "def gibbs_sampling(sampler, state, steps):\n",
    "    return range_gibbs_sampling(sampler, state, steps - 1, steps)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def h_ps(model, v):\n",
    "    return sigmoid(model.W @ v + model.c)\n",
    "\n",
    "\n",
    "class BlockSampler:\n",
    "    def __init__(self, model, active_index=None):\n",
    "        self.model = model\n",
    "        self.active_index = active_index\n",
    "    \n",
    "    def sample(self, state, index):\n",
    "        state = deepcopy(state)\n",
    "        \n",
    "        h, v = state\n",
    "        \n",
    "        if index == 0:\n",
    "            ps = h_ps(self.model, v)\n",
    "        else:\n",
    "            ps = sigmoid(self.model.W.T @ h + self.model.b)\n",
    "        \n",
    "        ai = self.active_index[index] if self.active_index else slice(None)\n",
    "        state[index][ai] = sps.bernoulli.rvs(ps[ai])\n",
    "        \n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, W, b, c):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return RBM(self.W + other.W, self.b + other.b, self.c + other.c)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return RBM(self.W * other, self.b * other, self.c * other)\n",
    "    \n",
    "    __rmul__ = __mul__\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + other * -1\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return self * (1 / other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerator_grad(sample, model):\n",
    "    ps = h_ps(model, sample)\n",
    "    \n",
    "    return RBM(ps @ sample.T, sample, ps)\n",
    "\n",
    "\n",
    "def compute_grad(num_gibbs_steps, sample, model):\n",
    "    bs = BlockSampler(model)\n",
    "    _, gibbs_sample = gibbs_sampling(bs, [np.zeros_like(model.c), sample], num_gibbs_steps)\n",
    "\n",
    "    return numerator_grad(sample, model) - numerator_grad(gibbs_sample, model)\n",
    "\n",
    "\n",
    "def sgd(model, compute_grad, samples, batch_size, lr, steps):\n",
    "    for _ in tqdm(range(steps)):\n",
    "        batch_index = np.random.choice(np.arange(samples.shape[0]), size=batch_size, replace=False)\n",
    "        batch = samples[batch_index]\n",
    "        \n",
    "        grad = np.mean([compute_grad(sample.T, model) for sample in batch])\n",
    "        model = model + lr * grad\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, samples, num_classes, sampling_steps):\n",
    "    bs = BlockSampler(model, [slice(None), slice(samples.shape[1], None)])\n",
    "    samples = np.hstack([samples, np.zeros((samples.shape[0], num_classes))])\n",
    "    answer = []\n",
    "    \n",
    "    for sample in tqdm(samples):\n",
    "        states = range_gibbs_sampling(bs, [np.zeros_like(model.c), sample.T], \n",
    "                                      sampling_steps * 2 // 3, sampling_steps)\n",
    "        visibles = np.squeeze(np.array([v for h, v in states]))\n",
    "        answer.append(np.mean(visibles[:, -num_classes:], axis=0).argmax())\n",
    "    \n",
    "    return np.array(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_impl(image, num_bins=16):\n",
    "    pixels = image.ravel()\n",
    "    \n",
    "    borders = np.linspace(np.min(pixels), np.max(pixels), num_bins, endpoint=False)\n",
    "    bins = np.digitize(pixels, borders)\n",
    "    \n",
    "    values, counts = np.unique(bins, return_counts=True)\n",
    "\n",
    "    all_counts = np.zeros((num_bins,))\n",
    "    all_counts[values - 1] = counts\n",
    "    probs = all_counts / all_counts.sum()\n",
    "    \n",
    "    omega = np.cumsum(probs)\n",
    "    mu = np.cumsum(np.arange(1, num_bins + 1) * probs)\n",
    "\n",
    "    omega_cut = omega[:-1]\n",
    "    mu_cut = mu[:-1]\n",
    "    sigma = ((mu[-1] * omega_cut - mu_cut) ** 2) / (omega_cut * (1 - omega_cut))\n",
    "    k_opt = np.argmax(sigma)\n",
    "    \n",
    "    binarized_mask = np.ones_like(pixels)\n",
    "    binarized_mask[pixels < borders[k_opt + 1]] = 0\n",
    "    binarized_mask = binarized_mask.reshape(image.shape[:2])\n",
    "    \n",
    "    return binarized_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = mnist['images'].shape[0]\n",
    "images = np.asmatrix(np.array([otsu_impl(image) for image in mnist['images']]).reshape((num_samples, -1)))\n",
    "target = np.zeros((num_samples, 10))\n",
    "target[np.arange(num_samples), mnist['target']] = 1\n",
    "\n",
    "train_size = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asmatrix(np.hstack([images, target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_model(visible, hidden):\n",
    "    W = np.asmatrix(np.random.normal(size=(hidden * visible)).reshape(hidden, visible))\n",
    "    b = np.asmatrix(np.zeros((visible,))).T\n",
    "    c = np.asmatrix(np.zeros((hidden,))).T\n",
    "    \n",
    "    return RBM(W, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = initial_model(data.shape[1], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:14<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "model = sgd(rbm, partial(compute_grad, 10), data[:train_size], 100, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:37<00:00,  7.88it/s]\n"
     ]
    }
   ],
   "source": [
    "answer = predict(model, images[train_size:], 10, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898989898989899"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(answer == target[train_size:].argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## То же самое нейронкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_std = images.std(axis=0)\n",
    "images_std[images_std == 0] = 1\n",
    "\n",
    "normalized_images = (images - images.mean(axis=0)) / images_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_placeholder = tf.placeholder(dtype=tf.float32, shape=(batch_size, images.shape[1]))\n",
    "target_placeholder = tf.placeholder(dtype=tf.int32, shape=(batch_size, 10))\n",
    "\n",
    "output = tf.nn.relu(tf.layers.dense(input_placeholder, 50))\n",
    "output = tf.nn.relu(tf.layers.dense(output, 40))\n",
    "output = tf.nn.relu(tf.layers.dense(output, 20))\n",
    "output = tf.layers.dense(output, 10)\n",
    "result = tf.argmax(output, axis=1)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(target_placeholder, output)\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = normalized_images[:train_size]\n",
    "train_target = target[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07115312\n",
      "6.408492e-05\n",
      "1.8792354e-05\n",
      "9.001453e-06\n",
      "4.4420854e-06\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_losses = []\n",
    "\n",
    "for _ in range(steps):\n",
    "    batch_index = np.random.choice(np.arange(train_X.shape[0]), size=batch_size, replace=False)\n",
    "    batch = train_X[batch_index]\n",
    "    batch_target = train_target[batch_index]\n",
    "\n",
    "    batch_loss, _ = sess.run([loss, optimizer], feed_dict={\n",
    "        input_placeholder: batch, target_placeholder: batch_target})\n",
    "    \n",
    "    batch_losses.append(batch_loss)\n",
    "    \n",
    "    if len(batch_losses) == 1000:\n",
    "        print(np.mean(batch_losses))\n",
    "        batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "\n",
    "for image in normalized_images[train_size:]:\n",
    "    batch = np.vstack([image, normalized_images[:batch_size - 1]])\n",
    "    answer.append(sess.run(result, feed_dict={input_placeholder: batch})[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8552188552188552"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(answer == target[train_size:].argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
